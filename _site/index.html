<!DOCTYPE html>
<html>
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>DIAG</title>
    <meta name="viewport" content="width=device-width, user-scalable=0">
    <meta name="description" content="In the DGIST Intelligence Augmentation Group (DIAG), we do research on the intersection of <u>Human-Computer Interaction</u> and <u>Artificial Intelligence</u>. Our focus lies in the study and development of <u>hybrid intelligence systems</u>, which integrate the power of both human and machine intelligence. Our objective is to address complex computational and social problems through the <u>design of novel and effective human-AI interactions</u> for these systems.">
    <link rel="canonical" href="http://localhost:4000/">

    <!-- Custom CSS & Bootstrap Core CSS - Uses Bootswatch Flatly Theme: http://bootswatch.com/flatly/ -->
    <link rel="stylesheet" href="/style.css">

    <!-- Custom Fonts -->
    <link rel="stylesheet" href="/css/font-awesome/css/font-awesome.min.css">
    <link href="//fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">

    <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon-32x32.png">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

    <body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">
     <!-- Navigation -->
    <nav class="navbar navbar-custom navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-main-collapse">
                    <i class="fa fa-bars"></i>
                </button>
                  <a class="navbar-brand page-scroll" href="#page-top">
                    <img src="/img/logo_small_new.png" alt="diag logo" width="27" style="margin-right: 7px; margin-top: -4px; float: left;">
                    <span style="font-size: 27px;"> DIAG</span>
                  </a>

            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse navbar-right navbar-main-collapse">
                <ul class="nav navbar-nav">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#joinus">Join Us</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#people">People</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#publications">Publications</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#projects">Projects</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#contact">Contact</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

        <!-- Intro Header -->
    <header class="intro">
        <div class="intro-body">
            <div class="container">
                <div class="row">
                  <br><br><br>
                    <div class="col-md-10 col-md-offset-1" style="background: rgba(0, 0, 0, .6); padding-top: 20px; padding-bottom: 50px;">
                        <h1 class="brand-heading">DIAG</h1>
                        <p class="intro-text">In the DGIST Intelligence Augmentation Group (DIAG), we do research on the intersection of <u>Human-Computer Interaction</u> and <u>Artificial Intelligence</u>. Our focus lies in the study and development of <u>hybrid intelligence systems</u>, which integrate the power of both human and machine intelligence. Our objective is to address complex computational and social problems through the <u>design of novel and effective human-AI interactions</u> for these systems.<br>
                        <a href="#joinus" class="btn btn-circle page-scroll">
                            <i class="fa fa-angle-double-down animated"></i>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </header>

        <!-- Join Us Section -->
    <section id="joinus" class="container content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>JOIN US</h2>
                <p>We are looking for motivated and well-qualified students who are passionate about designing and implementing human-AI hybrid intelligent systems to address real world problems.</p>
                <p style="margin: 0px;">If you are interested in joining our group and doing research in the areas of Human-Computer Interaction, Human-AI Interaction, Crowdsourcing,
                Human Computation, or any other related domains, please send your CV to <a href="mailto:diag.dgist@gmail.com">diag.dgist@gmail.com</a>.</p>
            </div>
        </div>
    </section>

    <!-- Peoples Section -->

<section id="people" class="container content-section text-center">
	<div class="row">
		<div class="col-lg-8 col-lg-offset-2">
			<h2>People</h2>
			<div class="row">
				<!--img src="/img/group_photo_2022fall_1.jpeg" alt="group_photo" width="49%" style="display:inline-block;">
				<img src="/img/group_photo_2022fall_2.jpeg" alt="group_photo" width="49%" style="display:inline-block;"-->
				<img src="/img/group_photo_2023spring.jpeg" alt="group_photo" width="49%" style="display:inline-block;">
				<br>
				<p>DIAG Group Photo 2023 Spring Term</p>
			</div>
			<br><br><br><br>
		</div>




		<div class="row">
			<div class="col-md-12">
				<h3>Professor</h3>
				<div class="photoContainer">
					<img src="/img/jean_profile2023.jpeg" alt="Jean's profile photo with her face">
				</div>
				<p><a href="https://jyskwon.github.io/">Jean Y. Song</a><br>
				  Assistant Professor</p>
			</div>
		</div>
		<br><br><br>

		<h3>Graduate Students</h3>

		<div class="row">
			<div class="col-md-3">
				<div class="photoContainer">
					<img src="/img/chanwoo_profile_picture.jpg" alt="Profile photo with his/her face">
				</div>
				<p><a href="">Chanwoo Park</a><br>
				  Ph.D. Student</p>
			</div>
			<div class="col-md-3">
				<div class="photoContainer">
					<img src="/img/dokyun_profile_picture.jpg" alt="Profile photo with his/her face">
				</div>
				<p><a href="">Dokyun Lee</a><br>
				  Ph.D. Student</p>
			</div>
			<div class="col-md-3">
				<div class="photoContainer">
					<img src="/img/yeonsun_profile_picture.jpg" alt="Profile photo with his/her face">
				</div>
				<p><a href="">Yeonsun Yang</a><br>
				  Ph.D. Student</p>
			</div>
			<div class="col-md-3">
				<div class="photoContainer">
					<img src="/img/sungmin_profile_picture.jpg" alt="Profile photo with his/her face">
				</div>
				<p><a href="">Sungmin Ha</a><br>
				  Ph.D. Student</p>
			</div>
		</div>
		<br><br><br>

		<h3>Undergraduate Students</h3>

		<div class="row">
			<div class="col-md-3">
				<div class="photoContainer">
					<img src="/img/dain_profile_picture.jpg" alt="Profile photo with his/her face">
				</div>
				<p><a href="">Dain Kim</a><br>
				  Undergraduate Research Intern</p>
			</div>
			<div class="col-md-3">
				<div class="photoContainer">
					<img src="/img/sihwan_profile_picture.jpg" alt="Profile photo with his/her face">
				</div>
				<p><a href="">Sihwan Seok</a><br>
				  Undergraduate Research Intern</p>
			</div>
			<div class="col-md-3">
				<div class="photoContainer">
					<img src="/img/sungmin_ju_profile_picture.jpg" alt="Profile photo with his/her face">
				</div>
				<p><a href="">Sungmin Ju</a><br>
				  Undergraduate Research Intern</p>
			</div>
			<div class="col-md-3">
				<div class="photoContainer">
					<img src="/img/subin_profile_picture.jpg" alt="Profile photo with his/her face">
				</div>
				<p><a href="">Subin Jo</a><br>
				  Undergraduate Research Intern</p>
			</div>
		</div>
		<br><br><br>
		<div class="row">
			<div class="col-md-3">
				<div class="photoContainer">
					<img src="/img/huidam_profile_picture.jpg" alt="Profile photo with his/her face">
				</div>
				<p><a href="">Huidam Woo</a><br>
				  Undergraduate Research Intern</p>
			</div>
			<div class="col-md-3">
				<div class="photoContainer">
					<img src="/img/KMS_profile_picture.jpg" alt="Profile photo with his/her face">
				</div>
				<p><a href="">Minseong Kim</a><br>
				  Undergraduate Research Intern</p>
			</div>
			<div class="col-md-3">
				<div class="photoContainer">
					<img src="/img/chan_profile_picture.jpg" alt="Profile photo with his/her face">
				</div>
				<p><a href="">Chan Lee</a><br>
				  Undergraduate Research Intern</p>
			</div>
		</div>
		<br><br><br>
		</div>

		<div class="col-lg-8 col-lg-offset-2">
			<h3>Alumni</h3>
			<ul style="font-size: 18px; text-align:left;">
				<li>
					Ahyeon Shin, Undergrad Intern (DGIST), Winter 2023
				</li>
				<li>
					SangEun Seo, Undergrad Intern (UNIST), Winter 2023
				</li>
				<li>
					Chanyu Moon, Undergrad Intern (DGIST), Winter 2023
				</li>
				<li>
					Gunuk Nam, Undergrad Intern (Handong Global University), Winter 2023
				</li>
				<li>
					Na Young Kim, Undergrad Intern (DGIST), Winter 2022 - Winter 2023
				</li>
				<li>
					Hojin Jin, Undergrad Intern (DGIST), Winter 2022 - Fall 2022
				</li>
				<li>
					Hyeonho Kwon, Undergrad Intern (DGIST), Winter 2022 - Fall 2022
				</li>
				<li>
					Gi Won Lee, Undergrad Intern (DGIST), Winter 2022 - Fall 2022
				</li>
				<li>
					Giwa Osaruiyobo Henrietta, Graduate Intern (DGIST), Summer 2022
				</li>

			</ul>
		</div>
	</div>
</section>

        <!-- Publications Section -->
    <section id="publications" class="container content-section">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2 style="text-align: center;">Publications</h2>

                <h3 style="text-align: center;"><strong>Conference and Journal Papers</strong></h3>
                  <ul style="font-size: 18px;">
                    <li>
                      <b>Jean Y. Song</b>*, Sangwook Lee*, Jisoo Lee, Mina Kim, and Juho Kim.
                      "<a href="/publications/CHI2023_ModSandbox.pdf">ModSandbox: Facilitating Online Community Moderation Through Error Prediction and Improvement of Automated Rules.
                      </a>"
                      In Proceedings of the ACM/SIGCHI Conference on Human Factors in Computing Systems (CHI 2023). (* Equal contribution)
                    </li>
                    <li>
                      Seoyun Son, Junyoung Choi, Sunjae Lee, <b>Jean Y. Song</b>, and Insik Shin.
                      "<a href="/publications/CHI2023_OnlineMeeting.pdf">It is Okay to be Distracted: How Real-time Transcriptions Facilitate Online Meeting with Distraction.
                      </a>"
                      In Proceedings of the ACM/SIGCHI Conference on Human Factors in Computing Systems (CHI 2023).
                    </li>
                    <li>
                      Sunjae Lee, Hoyoung Kim, Sijung Kim, Sangwook Lee, Hyosu Kim, <b>Jean Y. Song</b>, Steven Y. Ko, Sangeun Oh, and Insik Shin.
                      <a href="/publications/mobicom22-a-mash.pdf">A-Mash: Providing Single-app Illusion for Multi-app Use through User-centric UI Mashup.
                      </a>
                      In Proceedings of the International Conference On Mobile Computing And Networking (MobiCom 2022).
                    </li>
                    <li>
                      Yoonjoo Lee, John Joon Young Chung, Taesoo Kim, <b>Jean Y. Song</b>, and Juho Kim.
                      <a href="/publications/CHI2022_Promptiverse.pdf">Promptiverse: Scalable Generation of Scaffolding Prompts through Human-AI Knowledge Graph Annotation.
                      </a>
                      In Proceedings of the ACM/SIGCHI Conference on Human Factors in Computing Systems (CHI 2022).
                    </li>
                    <li>
                      Sunjae Lee, Hayeon Lee, Hoyoung Kim, Sangmin Lee, Jeong Woon Choi, Yuseung Lee, Seono Lee, Ahyeon Kim, <b>Jean Y. Song</b>, Sangeun Oh, Steven Y. Ko, and Insik Shin.
                      <a href="/publications/mobicom21-fluid-xp.pdf">FLUID-XP: Flexible User Interface Distribution forCross-Platform Experience.
                      </a>
                      In Proceedings of the International Conference On Mobile Computing And Networking (MobiCom 2021).
                    </li>
                    <li>
                      Zhefan Ye, <b>Jean Y. Song</b>, Zhiqiang Sui, Stephen Hart, Jorge Vilchis, Arbor, Walter S. Lasecki, and Odest C. Jenkins.
                      <a href="/publications/IUI2021_human-in-the-loop.pdf">Human-in-the-loop Pose Estimation via Shared Autonomy.
                      </a>
                      In Proceedings of the ACM International Conference on Intelligent User Interfaces (IUI 2021).
                      <font color="#FFC300">Best Paper Honorable Mention</font>
                    </li>
                    <li>
                      Stephan J. Lemmer, <b>Jean Y. Song</b>, and Jason J. Corso.
                      <a href="/publications/CHI2021_VOT.pdf">Crowdsourcing More Effective Initializations for Single-target Trackers Through Automatic Re-querying.
                      </a>
                      In Proceedings of the ACM/SIGCHI Conference on Human Factors in Computing Systems (CHI 2021).
                    </li>
                    <li>
                      Yoonjoo Lee, John Joon Young Chung, <b>Jean Y. Song</b>, Minsuk Chang, and Juho Kim.
                      <a href="/publications/CHI2021_SWM.pdf">Personalizing Ambience and Illusionary Presence: How People Use "Study with Me" Videos to Create Effective Studying Environments.
                      </a>
                      In Proceedings of the ACM/SIGCHI Conference on Human Factors in Computing Systems (CHI 2021).
                    </li>
                    <li>
                      <b>Jean Y. Song</b>, John Joon Young Chung, David F. Fouhey, and Walter S. Lasecki.
                      <a href="/publications/CReference_CSCW2020.pdf">C-Reference: Improving 2D to 3D Object Pose Estimation Accuracy via Crowdsourced Joint Object Estimation.
                      </a>
                      In Proceedings of the ACM International Conference on Computer Supported Cooperative Work and Social Computing (CSCW 2020).
                    </li>
                    <li>
                      Divya Ramesh, Anthony Z. Liu, Andres J. Echeverria, <b>Jean Y. Song</b>, Nicholas R. Waytowich, and Walter S. Lasecki.
                      <a href="/publications/contrast_effect_AAMAS2020.pdf">Yesterday’s Reward is Today’s Punishment: Contrast Effects in Human Feedback to Reinforcement Learning Agents.
                      </a>
                      In Proceedings of the International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2020).
                      <font color="#FFC300">Pragnesh Jay Modi Best Student Paper</font>
                    </li>
                    <li>
                      Yan Chen, Maulishree Pandey, <b>Jean Y. Song</b>, Walter S. Lasecki, and Steve Oney.
                      <a href="/publications/GUITesting_CHI2020.pdf">Improving Crowd-Supported GUI Testing with Structural Guidance.
                      </a>
                      In Proceedings of the ACM/SIGCHI Conference on Human Factors in Computing Systems (CHI 2020).
                    </li>
                    <li>John Joon Young Chung, <b>Jean Y. Song</b>, Sindhu Kutty, Sungsoo (Ray) Hong, Juho Kim, and Walter S. Lasecki.
                      <a href="/publications/ManyThoughts_CSCW2019.pdf">Efficient Elicitation Approaches to Estimate Collective Crowd Answers.
                      </a>
                      In Proceedings of the ACM International Conference on Computer Supported Cooperative Work and Social Computing (CSCW 2019).
                      Austin, TX. <font color="#FFC300">Best Paper Honorable Mention</font>
                    </li>
                    <li><b>Jean Y. Song</b>, Raymond Fok, Juho Kim, and Walter S. Lasecki.
                      <a href="https://doi.org/10.1145/3237188">FourEyes:
                        Leveraging Tool Diversity as a Means to Improve Aggregate Accuracy in Crowdsourcing.
                      </a>
                      In ACM Transactions on Interactive Intelligent Systems, Volume 19, Issue 1, Article No. 3 (TiiS 2019).
                    </li>
                    <li><b>Jean Y. Song</b>, Stephan J. Lemmer, Michael Xieyang Liu, Shiyan Yan, Juho Kim, Jason J. Corso, and Walter S. Lasecki.
                      <a href="/publications/popup_IUI2019.pdf">Popup:
                        Reconstructing 3D Video Using Particle Filtering to Aggregate Crowd Responses.
                      </a>
                      In Proceedings of the ACM International Conference on Intelligent User Interfaces (IUI 2019).
                      Los Angeles, CA. <!--[25% Acceptance Rate]-->
                    <li> <b>Jean Y. Song</b>, Raymond Fok, Alan Lundgard, Fan Yang, Juho Kim, and Walter S. Lasecki.
                      <a href="/publications/IUI2018_FourEyes.pdf">Two Tools are Better Than One:
                        Tool Diversity as a Means of Improving Aggregate Crowd Performance.
                      </a>
                      In Proceedings of the ACM International Conference on Intelligent User Interfaces (IUI 2018).
                      Tokyo, Japan. <!--[23% Acceptance Rate]--><font color="#FFC300">Best Student Paper Honorable Mention</font>
                    </li>
                  </ul>
                <br><br>

                <h3 style="text-align: center;"><strong>Posters, Demos, and Workshop Papers</strong></h3>
                  <ul>
                    <li>Hyungyu Shin, Nabila Sindi, Yoonjoo Lee, Jaeryoung Ka, <b>Jean Y. Song</b>, and Juho Kim.
                      <a href="/publications/SIGCSE2022-poster-XDesign-paper.pdf">XDesign: Integrating Interface Design into Explainable AI Education.
                      </a>
                      In Proceedings of the ACM Technical Symposium on Computer Science Education (SIGCSE TS 2022).
                    </li>
                    <li>Andrew M. Vernier, <b>Jean Y. Song</b>, Edward Sun, Allison Kench, and Walter S. Lasecki.
                      <a href="/publications/corsica_UIST2019-poster.pdf">Towards Universal Evaluation of Image Annotation Interfaces.
                      </a>
                      In Proceedings of the ACM Symposium on User Interface Software and Technology (UIST 2019).
                      New Orleans, LA.
                    </li>
                    <li> <b>Jean Y. Song</b>, Raymond Fok, Fan Yang, Kyle Wang, Alan Lundgard, and Walter S. Lasecki.
                      <a href="/publications/GroupSight2017_ToolDiversity.pdf">Tool Diversity
                        as a Means of Improving Aggregate Crowd Performance on Image Segmentation Tasks.
                      </a>
                      In HCOMP Workshop on Human Computation for Image and Video Analysis (HCOMP GroupSight 2017).
                      Quebec City, Quebec. 2017.
                    </li>
                    <li> Sai R. Gouravajhala, <b>Jean Y. Song</b>, Jinyeong Yim, Raymond Fok, Yanda Huang, Fan Yang, Kyle Wang, Yilei An, and Walter S. Lasecki.
                      <a href="/publications/eureca_ci2017.pdf">Towards Hybrid Intelligence for Robotics.
                      </a>
                      In Collective Intelligence Conference (CI 2017). New York, NY.
                    </li>
                  </ul>


            </div>
        </div>
    </section>

        <!-- Projects Section -->
    <section id="projects" class="container content-section text-center">
        <div class="row">
                <h2>Projects</h2>

                <p>Our research projects include but are not limited to the following list.
                We are open to discuss new project ideas in the topic of Human-Computer Interaction, Human-AI Interaction, Crowdsourcing,
                Human Computation, or any other related domains.
                Please feel free to contact us if you have exciting ideas.</p>
                <br>

                <div class="container">
                  <div class="row">
                    <div class="col-md-8" style="font-size: 18px; text-align:left;">
                      <p><u>Facilitating Online Community Moderation using AI Techniques</u></p>
                      <p>Communities on social platforms have a group of users who volunteer to moderate their communities, called online moderators. They respond to the behavior of community members that violate rules and work to improve overall interaction experiences between community members.
                        This project aims to build human-AI interaction tools to support moderators to more easily and transparently moderate their online communities.
                      </p>
                    </div>
                    <div class="col-md-4">
                      <br><br>
                      <img src="/img/proj_modsandbox.png" alt="" width="300">
                    </div>
                  </div>
                  <br>
                  <div class="row">
                    <div class="col-md-8" style="font-size: 18px; text-align:left;">
                      <p><u>Improving Facial Emotion Recognition for both Human and AI</u></p>
                      <p>This project focuses on enhancing Facial Emotion Recognition(FER) for individuals who struggle with recognizing facial expressions, as well as for current models with low FER performance.
                        To address these challenges, we developed a gamified application called "Find the Bot!" that re-labels FER datasets and trains individuals with difficulties in recognizing facial emotions simultaneously.
                        Our vision is to improve FER abilities for individuals with weak FER, leading to enhanced relationship quality, social acceptance, and increased social productivity, while also contributing to the development of reliable multi-labeling for facial expression datasts.</p>
                    </div>
                    <div class="col-md-4">
                      <br><br><br><br>
                      <img src="/img/proj_fergame.png" alt="" width="300">
                    </div>
                  </div>
                  <br>
                  <div class="row">
                    <div class="col-md-8" style="font-size: 18px; text-align:left;">
                      <p><u>Reducing Negative Emotions for Crowd Workers Exposed to Disturbing Content</u></p>
                      <p>Often times crowd workers who do content moderation or data annotations are exposed to harmful content in their daily routines.
                        This project explores UI intervention techniques that can prevent crowd workers from getting too much negative emotional impacts when conducting these tasks.
                        Through this study, we aim to find ways to maintain the quality and cost of the crowdsourced work while protecting the emotions and mental health of crowd workers.</p>
                    </div>
                    <div class="col-md-4">
                      <br><br>
                      <img src="/img/proj_panas.jpg" alt="" width="300">
                    </div>
                  </div>
                  <br><br><br>
                  <div class="row">
                    <div class="col-md-8" style="font-size: 18px; text-align:left;">
                      <p><u>Continual Learning from a Data Science Perspective</u></p>
                      <p>Implementing a model created in a controlled environment into the real world requires solving the problem of Catastrophic Forgetting.
                        To solve that problem, we seek to draw inspiration from the Human Complementary Learning Systems (CLS) from a data science perspective.
                        Through this research, we hope that the model created in a controlled environment can continuously learn in the real world, and through this, the controlled model can be applied to daily life.</p>
                    </div>
                    <div class="col-md-4">
                      <br><br><br><br>
                      <img src="/img/proj_cl.png" alt="" width="300">
                    </div>
                  </div>
                  <br><br><br>
                  <div class="row">
                    <div class="col-md-8" style="font-size: 18px; text-align:left;">
                      <p><u>Augmenting QnA Dataset for Technical Documents with Crowdsourcing</u></p>
                      <p>This project proposes a new sentence structuring method and crowdsourcing interface to augment rich Korean dataset in text documents specialized in technology and science.
                        Our novel authoring tool enables to efficiently generating various question and answer pairs for technical documentation by breaking down sentences into elements that can be recombined to form new sentences.</p>
                    </div>
                    <div class="col-md-4">
                      <br>
                      <img src="/img/proj_koreanannotation.png" alt="" width="300">
                    </div>
                  </div>
                </div>
        </div>
    </section>

        <!-- Contact Section -->
    <section id="contact" class="container content-section text-center">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
                <h2>Contact</h2>
                <p>​
                  We welcome collaborations!<br>
                  If you have any questions or would like to hear more about our research, please feel free to shoot us an email:
                  <a href="mailto:diag.dgist@gmail.com">diag.dgist@gmail.com</a>
                </p>
                <br>
                <!--ul class="list-inline banner-social-buttons">
                    
                </ul-->
            </div>
        </div>
    </section>

        <!-- Footer -->
    <footer>
        <div class="container text-center">
            <p>Copyright &copy; diag.kr 2023</p>
        </div>
    </footer>

     <!-- jQuery Version 1.11.0 -->
    <script src="/js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="/js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="/js/jquery.easing.min.js"></script>

    <!-- Google Maps API Key - Use your own API key to enable the map feature. More information on the Google Maps API can be found at https://developers.google.com/maps/ -->
    <script type="text/javascript" src="https://maps.googleapis.com/maps/api/js?key=AIzaSyCRngKslUGJTlibkQ3FkfTxj3Xss1UlZDA&sensor=false"></script>

    <!-- Custom Theme JavaScript -->
    <script src="/js/grayscale.js"></script>

    </body>
</html>
